{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import gc\n",
    "import h5py\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moodNamePrintFromLabel(n):\n",
    "  if n == 0: result = 'angry '\n",
    "  elif n == 1: result = 'disgust '\n",
    "  elif n == 2: result = 'fear'\n",
    "  elif n == 3: result = 'happy'\n",
    "  elif n == 4: result = 'sad'\n",
    "  elif n == 5: result = 'surprise'\n",
    "  elif n == 6: result = 'neutral'\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3995/3995 [00:01<00:00, 3214.19it/s]\n",
      "100%|██████████| 436/436 [00:00<00:00, 3428.90it/s]\n",
      "100%|██████████| 4097/4097 [00:01<00:00, 3354.77it/s]\n",
      "100%|██████████| 7215/7215 [00:02<00:00, 3395.30it/s]\n",
      "100%|██████████| 4830/4830 [00:01<00:00, 3364.68it/s]\n",
      "100%|██████████| 3171/3171 [00:00<00:00, 3391.13it/s]\n",
      "100%|██████████| 4965/4965 [00:01<00:00, 3126.06it/s]\n",
      "100%|██████████| 705/705 [00:00<00:00, 2981.91it/s]\n",
      "100%|██████████| 717/717 [00:00<00:00, 3100.65it/s]\n",
      "100%|██████████| 281/281 [00:00<00:00, 2941.01it/s]\n",
      "100%|██████████| 4772/4772 [00:01<00:00, 2827.77it/s]\n",
      "100%|██████████| 1982/1982 [00:00<00:00, 2970.20it/s]\n",
      "100%|██████████| 1290/1290 [00:00<00:00, 2949.56it/s]\n",
      "100%|██████████| 2524/2524 [00:00<00:00, 2928.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_directory(directory, target_size=(48, 48)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'sad': 4, 'surprise': 5, 'neutral': 6}\n",
    "    for label_name, label_index in label_map.items():\n",
    "        class_dir = os.path.join(directory, label_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        for img_name in tqdm(os.listdir(class_dir)):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, target_size)\n",
    "                images.append(img.reshape(target_size[0], target_size[1], 1))\n",
    "                labels.append(label_index)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Load FER2013 images\n",
    "X_fer2013, y_fer2013 = load_images_from_directory('Train Image Data/FER-2013')\n",
    "\n",
    "# Load AffectNet images\n",
    "X_affectnet, y_affectnet = load_images_from_directory('Train Image Data/AffectNet')\n",
    "\n",
    "# Load RAF-DB images\n",
    "X_RAF, y_RAF = load_images_from_directory('Train Image Data/RAF-DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of FER2013 images: (28709, 224, 224, 3)\n",
      "Shape of AffectNet images: (0, 224, 224, 3)\n",
      "Shape of Rafdb images: (12271, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_image(image, target_size=(224, 224)):\n",
    "    image = image.astype(np.float32)\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def preprocess_and_save_images_with_labels(images, labels, output_file, dataset_name_image, dataset_name_label, batch_size=50):\n",
    "    num_batches = len(images) // batch_size + (1 if len(images) % batch_size != 0 else 0)\n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        # Create datasets for images and labels\n",
    "        processed_shape = (len(images), 224, 224, 3)\n",
    "        dataset_image = hf.create_dataset(dataset_name_image, shape=processed_shape, dtype=np.float32)\n",
    "        dataset_label = hf.create_dataset(dataset_name_label, data=labels, dtype=np.uint8)\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min((batch_idx + 1) * batch_size, len(images))\n",
    "            batch_images = images[start_idx:end_idx]\n",
    "            processed_batch_images = np.array([preprocess_image(image) for image in batch_images], dtype=np.float32)\n",
    "            dataset_image[start_idx:end_idx] = processed_batch_images\n",
    "            del batch_images, processed_batch_images\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess images in batches and save to HDF5 files\n",
    "preprocess_and_save_images_with_labels(X_fer2013, y_fer2013, 'output files/fer2013_processed.h5', 'fer2013_images', 'fer2013_labels')\n",
    "preprocess_and_save_images_with_labels(X_affectnet, y_affectnet, 'output files/affectnet_processed.h5', 'affectnet_images', 'affectnet_labels')\n",
    "preprocess_and_save_images_with_labels(X_RAF, y_RAF, 'output files/rafdb_processed.h5', 'rafdb_images', 'rafdb_labels')\n",
    "\n",
    "# Check the shapes of the processed arrays\n",
    "with h5py.File('output files/fer2013_processed.h5', 'r') as hf:\n",
    "    fer2013_images = hf['fer2013_images']\n",
    "    print(\"Shape of FER2013 images:\", fer2013_images.shape)\n",
    "\n",
    "with h5py.File('output files/affectnet_processed.h5', 'r') as hf:\n",
    "    affectnet_images = hf['affectnet_images']\n",
    "    print(\"Shape of AffectNet images:\", affectnet_images.shape)\n",
    "\n",
    "with h5py.File('output files/rafdb_processed.h5', 'r') as hf:\n",
    "    rafdb_images = hf['rafdb_images']\n",
    "    print(\"Shape of Rafdb images:\", rafdb_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved to output files/combined_images_labels.h5\n",
      "Datasets in output files/combined_images_labels.h5:\n",
      " - combined_images: (40980, 224, 224, 3)\n",
      " - combined_labels: (40980,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_data_from_hdf5_in_chunks(file_path, dataset_name_image, dataset_name_label, chunk_size=200):\n",
    "    \"\"\"Load images and labels from an HDF5 file in chunks.\"\"\"\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        images_dataset = hf[dataset_name_image]\n",
    "        labels_dataset = hf[dataset_name_label]\n",
    "        \n",
    "        num_samples = len(labels_dataset)\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for start_idx in range(0, num_samples, chunk_size):\n",
    "            end_idx = min(start_idx + chunk_size, num_samples)\n",
    "            images_chunk = images_dataset[start_idx:end_idx]\n",
    "            labels_chunk = labels_dataset[start_idx:end_idx]\n",
    "            images.append(images_chunk)\n",
    "            labels.append(labels_chunk)\n",
    "        \n",
    "        # Convert lists to arrays\n",
    "        images = np.concatenate(images, axis=0)\n",
    "        labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def save_combined_data(output_file, images, labels, image_dataset_name='combined_images', label_dataset_name='combined_labels'):\n",
    "    \"\"\"Save combined images and labels to an HDF5 file.\"\"\"\n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        num_samples = images.shape[0]\n",
    "        # Create datasets for images and labels\n",
    "        hf.create_dataset(image_dataset_name, data=images, dtype=np.float32)\n",
    "        hf.create_dataset(label_dataset_name, data=labels, dtype=np.uint8)\n",
    "    \n",
    "    print(f\"Combined dataset saved to {output_file}\")\n",
    "\n",
    "# Load datasets from HDF5 files\n",
    "X_fer2013, y_fer2013 = load_data_from_hdf5_in_chunks('output files/fer2013_processed.h5', 'fer2013_images', 'fer2013_labels')\n",
    "# X_affectnet, y_affectnet = load_data_from_hdf5_in_chunks('output files/affectnet_processed.h5', 'affectnet_images', 'affectnet_labels')\n",
    "X_RAF, y_RAF = load_data_from_hdf5_in_chunks('output files/rafdb_processed.h5', 'rafdb_images', 'rafdb_labels')\n",
    "\n",
    "\n",
    "# Concatenate datasets\n",
    "X_combined = np.concatenate((X_fer2013, X_RAF), axis=0)\n",
    "y_combined = np.concatenate((y_fer2013, y_RAF), axis=0)\n",
    "\n",
    "# Save the concatenated dataset to a new HDF5 file\n",
    "output_combined_file = 'output files/combined_images_labels.h5'\n",
    "save_combined_data(output_combined_file, X_combined, y_combined)\n",
    "\n",
    "# Function to list datasets in an HDF5 file\n",
    "def list_datasets(file_path):\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        print(f\"Datasets in {file_path}:\")\n",
    "        for dataset in hf:\n",
    "            print(f\" - {dataset}: {hf[dataset].shape}\")\n",
    "\n",
    "# List datasets in the combined HDF5 file\n",
    "list_datasets('output files/combined_images_labels.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets in output files/fer2013_processed.h5:\n",
      " - fer2013_images: (28709, 224, 224, 3)\n",
      " - fer2013_labels: (28709,)\n",
      "Datasets in output files/affectnet_processed.h5:\n",
      " - affectnet_images: (0, 224, 224, 3)\n",
      " - affectnet_labels: (0,)\n",
      "Datasets in output files/rafdb_processed.h5:\n",
      " - rafdb_images: (12271, 224, 224, 3)\n",
      " - rafdb_labels: (12271,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Function to list datasets in an HDF5 file\n",
    "def list_datasets(file_path):\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        print(f\"Datasets in {file_path}:\")\n",
    "        for dataset in hf:\n",
    "            print(f\" - {dataset}: {hf[dataset].shape}\")\n",
    "\n",
    "# List datasets in each HDF5 file\n",
    "list_datasets('output files/fer2013_processed.h5')\n",
    "list_datasets('output files/affectnet_processed.h5')\n",
    "list_datasets('output files/rafdb_processed.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
