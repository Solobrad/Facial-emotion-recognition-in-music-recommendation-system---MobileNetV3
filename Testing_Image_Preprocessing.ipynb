{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import gc\n",
    "import h5py\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv2D, Dropout, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moodNamePrintFromLabel(n):\n",
    "  if n == 0: result = 'angry '\n",
    "  elif n == 1: result = 'disgust '\n",
    "  elif n == 2: result = 'fear'\n",
    "  elif n == 3: result = 'happy'\n",
    "  elif n == 4: result = 'sad'\n",
    "  elif n == 5: result = 'surprise'\n",
    "  elif n == 6: result = 'neutral'\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 958/958 [00:00<00:00, 7264.05it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 7463.89it/s]\n",
      "100%|██████████| 1024/1024 [00:00<00:00, 7554.29it/s]\n",
      "100%|██████████| 1774/1774 [00:00<00:00, 7645.09it/s]\n",
      "100%|██████████| 1247/1247 [00:00<00:00, 7400.22it/s]\n",
      "100%|██████████| 831/831 [00:00<00:00, 7515.54it/s]\n",
      "100%|██████████| 1233/1233 [00:00<00:00, 7510.06it/s]\n",
      "100%|██████████| 162/162 [00:00<00:00, 6521.83it/s]\n",
      "100%|██████████| 160/160 [00:00<00:00, 5384.04it/s]\n",
      "100%|██████████| 74/74 [00:00<00:00, 6754.70it/s]\n",
      "100%|██████████| 1185/1185 [00:00<00:00, 6319.87it/s]\n",
      "100%|██████████| 478/478 [00:00<00:00, 6212.42it/s]\n",
      "100%|██████████| 329/329 [00:00<00:00, 6104.92it/s]\n",
      "100%|██████████| 680/680 [00:00<00:00, 6270.53it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_images_from_directory(directory, target_size=(48, 48)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'sad': 4, 'surprise': 5, 'neutral': 6}\n",
    "    for label_name, label_index in label_map.items():\n",
    "        class_dir = os.path.join(directory, label_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        for img_name in tqdm(os.listdir(class_dir)):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, target_size)\n",
    "                images.append(img.reshape(target_size[0], target_size[1], 1))\n",
    "                labels.append(label_index)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "# Load FER2013 images\n",
    "X_fer2013, y_fer2013 = load_images_from_directory('Test Image Data/FER-2013')\n",
    "\n",
    "# Load AffectNet images\n",
    "X_affectnet, y_affectnet = load_images_from_directory('Test Image Data/AffectNet')\n",
    "\n",
    "# Load RAF-DB images\n",
    "X_RAF, y_RAF = load_images_from_directory('Test Image Data/RAF-DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of FER2013 images: (7178, 224, 224, 3)\n",
      "Shape of AffectNet images: (0, 224, 224, 3)\n",
      "Shape of Rafdb images: (3068, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_image(image, target_size=(224, 224)):\n",
    "    image = image.astype(np.float32)\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = (image / 127.5) - 1\n",
    "    return image\n",
    "\n",
    "def preprocess_and_save_images_with_labels(images, labels, output_file, dataset_name_image, dataset_name_label, batch_size=50):\n",
    "    num_batches = len(images) // batch_size + (1 if len(images) % batch_size != 0 else 0)\n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        # Create datasets for images and labels\n",
    "        processed_shape = (len(images), 224, 224, 3)\n",
    "        dataset_image = hf.create_dataset(dataset_name_image, shape=processed_shape, dtype=np.float32)\n",
    "        dataset_label = hf.create_dataset(dataset_name_label, data=labels, dtype=np.uint8)\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min((batch_idx + 1) * batch_size, len(images))\n",
    "            batch_images = images[start_idx:end_idx]\n",
    "            processed_batch_images = np.array([preprocess_image(image) for image in batch_images], dtype=np.float32)\n",
    "            dataset_image[start_idx:end_idx] = processed_batch_images\n",
    "            del batch_images, processed_batch_images\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocess images in batches and save to HDF5 files with uniform names\n",
    "preprocess_and_save_images_with_labels(X_fer2013, y_fer2013, 'output files/fer2013_testing.h5', 'images', 'labels')\n",
    "preprocess_and_save_images_with_labels(X_affectnet, y_affectnet, 'output files/affectnet_testing.h5', 'images', 'labels')\n",
    "preprocess_and_save_images_with_labels(X_RAF, y_RAF, 'output files/rafdb_testing.h5', 'images', 'labels')\n",
    "\n",
    "# Check the shapes of the processed arrays\n",
    "with h5py.File('output files/fer2013_testing.h5', 'r') as hf:\n",
    "    fer2013_images = hf['images']\n",
    "    print(\"Shape of FER2013 images:\", fer2013_images.shape)\n",
    "\n",
    "with h5py.File('output files/affectnet_testing.h5', 'r') as hf:\n",
    "    affectnet_images = hf['images']\n",
    "    print(\"Shape of AffectNet images:\", affectnet_images.shape)\n",
    "\n",
    "with h5py.File('output files/rafdb_testing.h5', 'r') as hf:\n",
    "    rafdb_images = hf['images']\n",
    "    print(\"Shape of Rafdb images:\", rafdb_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
